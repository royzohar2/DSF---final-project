{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#receives a trained model\n",
    "\n",
    "def metrics_f(model , X_train ,X_test, y_train,y_test):\n",
    "    # Make predictions on the training and testing sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    train_rmse = np.sqrt(train_mse)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Train MSE:\", train_mse)\n",
    "    print(\"Test MSE:\", test_mse)\n",
    "    print(\"Train RMSE:\", train_rmse)\n",
    "    print(\"Test RMSE:\", test_rmse)\n",
    "    print(\"Train MAE:\", train_mae)\n",
    "    print(\"Test MAE:\", test_mae)\n",
    "    print(\"Train R2:\", train_r2)\n",
    "    print(\"Test R2:\", test_r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#receives a trained model\n",
    "\n",
    "def residual_plot(model , X_train ,X_test, y_train,y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate mean squared error on the training and testing sets\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "    # Print the mean squared error\n",
    "    print(\"Train MSE:\", train_mse)\n",
    "    print(\"Test MSE:\", test_mse)\n",
    "\n",
    "    # Create a residual plot\n",
    "    train_residuals = y_train_pred - y_train\n",
    "    test_residuals = y_test_pred - y_test\n",
    "    plt.scatter(y_train_pred, train_residuals, c='blue', marker='o', label='Training data')\n",
    "    plt.scatter(y_test_pred, test_residuals, c='green', marker='s', label='Testing data')\n",
    "    plt.xlabel('Predicted values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.hlines(y=0, xmin=0, xmax=50, lw=2, color='red')\n",
    "    plt.xlim([0, 50])\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#receives a trained model\n",
    "def feature_importances_LinearRegression(model,X_train):\n",
    "    # Print feature coefficients\n",
    "    for feature, coef in zip(X_train.columns, model.coef_):\n",
    "        print(\"{} coefficient: {:.3f}\".format(feature, coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_hyperparameter(X_train, y_train):\n",
    "    n_list = list(range(3, 30, 2))\n",
    "    # Define parameter grid to search\n",
    "    param_grid = {'n_neighbors': n_list,\n",
    "                  'weights': ['uniform', 'distance'], # equal weight or weight to each point proportional to its inverse distance\n",
    "                  'p': [1, 2], #for minkowski :  Manhattan distance or  Euclidean distance \n",
    "                  'leaf_size': [10, 20, 30],#for faster nearest neighbor search.\n",
    "                  'metric': ['euclidean', 'manhattan', 'minkowski']}#compute the distance between two points in the dataset\n",
    "                 \n",
    "\n",
    "   \n",
    "    knn = KNeighborsRegressor()\n",
    "\n",
    "    \n",
    "    grid_search = GridSearchCV(knn, param_grid,scoring='r2', verbose=4, cv=5)\n",
    " \n",
    "    # fit gridsearchcv\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print best parameters and best score\n",
    "    print('Best Parameters:', grid_search.best_params_)\n",
    "    print('Best Score:', grid_search.best_score_)\n",
    "\n",
    "    # create knn_best using best parameters\n",
    "    knn_best = KNeighborsRegressor(**grid_search.best_params_)\n",
    "    return knn_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one more model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
